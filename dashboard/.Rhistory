install.packages("swirl")
library(swirl)
library(swirl)
install_from_swirl("Regression Models")
swirl()
plot(child~parent, galton)
plot(jitter(child,4)~parent, galton)
regrline <- lm(child ~ parent, galton)
abline(regrline, lwd=3, col='red')
summary(regrline)
exit
exit9)
quit()
pnorm
pnorm(70, mean=80, sd=10)
pnorm(1223, mean=1100, sd=75)
sqrt(75/10)
sqrt(75/100)
sqrt(75/100)*2+1100
pow(0.5,4)
0.5^4
2*0.5^4
1/sqrt(1000)
1/(12*10)
(1/(12*10))/sqrt(1000)
sqrt(0.029)
ppois(10, lambda = 5*3)
75/10
1.64*sqrt(75/10)
1.64*sqrt(75/10)+1100
1.64*sqrt(75/100)+1100
1.64*75/10+1100
6*(0.5)^5
1/12
1/(12*sqrt(1000))
1/(12*sqrt(100))
sqrt(1/(12*1000))
sqrt(1/(12*100))
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
install.packages("AppliedPredictiveModeling")
install.packages("caret")
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
testIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[-testIndex,]
testing = adData[testIndex,]
training
testing
head(training)
head(testing)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
plot(training$CompressiveStrength,pch=1,col=cut2(training$FlyAsh,m=20))
library(Hmisc)
plot(training$CompressiveStrength,pch=1,col=cut2(training$FlyAsh,m=20))
plot(training$CompressiveStrength,pch=1,col=cut2(training$Age,m=20))
plot(training$CompressiveStrength,pch=1,col=cut2(training$Cement,m=20))
plot(training$CompressiveStrength,pch=1,col=cut2(training$FlyAsh,m=20))
plot(mixtures$CompressiveStrength,pch=1,col=cut2(mixtures$FlyAsh,m=20))
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
hist(training$Superplasticizer)
summary(training$Superplasticizer)
cols <- training[, grepl("^IL", names(training))]
cols
training(cols)
training[cols]
training(,cols)
training[],cols]
training[,cols]
training[cols,]
names(training)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
names(training)
cols <- training[, grepl("^IL", names(training))]
prresult <- prcomp(cols)
plot(prresult)
summary(prresult)
preProcess(cols, method='pca')
?preProcess
preProcess(cols, method='pca', thresh = 0.9)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
modfit<-train(diagnosis~.,method="lm", data=training)
modfit<-train(diagnosis~predictors,method="lm", data=training)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
training$predictors
modfit<-train(diagnosis~.,method="lm", data=training)
cols <- training[, grepl("^IL", names(training))]
modfit<-train(training$diagnosis~cols.,method="lm")
modfit<-train(training$diagnosis~cols,method="lm")
cols
modfit<-train(training$diagnosis~cols$.,method="lm")
modfit<-train(training$diagnosis~.,method="lm",data=cols)
newdata <- rbind(training$diagnosis, cols)
head(newdata)
training$diagnosis
newdata <- cbind(training$diagnosis, cols)
head(newdata)
colnames(newdata)
colnames(newdata)[1]<-diagnosis
colnames(newdata)[1]<-"diagnosis"
modfit<-train(diagnosis~.,method="lm",data=newdata)
modfit<-train(diagnosis~.,method="glm",data=newdata)
print(modfit)
pred<-predict(modfit, testing)
pred
print(pred)
modfit$results$Accuracy
pcadata <- preProcess(cols, method='pca', thresh = 0.8)
pcadata
pcadata$pcaComp
pcadata$data
pcadata$call
pcadata$dim
pcadata$bc
pcadata$yj
pcadata$et
pcadata$mean
pcadata$rotation
modfit<-train(diagnosis~pcadata$rotation.,method="glm",data=newdata)
modfit<-train(newdata$diagnosis~pcadata$rotation.,method="glm")
pcadata$rotation
modfit<-train(diagnosis~.,method="glm",data=newdata, preProcess="pcs")
modfit<-train(diagnosis~.,method="glm",data=newdata, preProcess="pca")
confusionMatrix(testing$diagnosis, predict(modfit, testing))
modfit<-train(diagnosis~.,method="glm",data=newdata)
confusionMatrix(testing$diagnosis, predict(modfit, testing))
install.packages('devtools')
library(devtools)
install_github('slidify','ramnathv')
install_github(slidifyLibraries,'ramnathv')
install_github('slidifyLibraries','ramnathv')
library(slidify)
install.packages(c("caTools", "cluster", "e1071", "fmsb", "fpc", "Hmisc", "htmltools", "httr", "jsonlite", "KernSmooth", "Lahman", "mclust", "NbClust", "Rcmdr", "RcmdrMisc", "rmarkdown", "roxygen2", "Rttf2pt1", "xtable"))
install.packages("quantmod")
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
set.seed(33833)
vowel.train$y
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
set.seed(33833)
model1 <- train(y~., method="rf", data=vowel.train)
library(caret)
model1 <- train(y~., method="rf", data=vowel.train)
model1
pred<-predict(model1, vowel.test)
pred
confusionMatrix(vowel.test$y, pred)
model2 <- train(y~., method="gbm", data=vowel.train)
pred2<-predict(model2, vowel.test)
confusionMatrix(vowel.test$y, pred2)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(64233)
model1 <- train(diagnosis~., method="rf", data=training)
model2 <- train(diagnosis~., method="gbm", data=training)
model3 <- train(diagnosis~., method="lda", data=training)
model3 <- train(diagnosis~., method="lda", data=training)
pred1 <- predict(model1, testing)
pred2 <- predict(model2, testing)
pred3 <- predict(model3, testing)
ï¿¼
qplot(pred1, pred2)
predF <- data.frame(pred1, pred2, pred3, diagnosis=testing$diagnosis)
combModFit <- train(diagnosis~.,method="rf",data=predF)
combPred <- predict(combModFit,predF)
combPred
confusionMatrix(combPred, testing$diagnosis)
confusionMatrix(pred1, testing$diagnosis)
confusionMatrix(pred2, testing$diagnosis)
confusionMatrix(pred3, testing$diagnosis)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233_)
set.seed(233)
model <- train(diagnosis~., method="lasso", data=training)
model <- train(CompressiveStrength~., method="lasso", data=training)
model
?plot.enet
plot(model)
?plot.enet
enet(training, training$CompressiveStrength)
model
model$method
model$modelInfo
model$fit
model$pred
model$modelType
model$results
model$finalModel
plot(model$finalModel)
library(lubridate)  # For year() function below
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(lubridate)  # For year() function below
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(forecast)
install.packages("forecast")
library(forecast)
?bat
?bats
bats(tstrain)
model<-bats(tstrain)
model
predict(model, testing)
?forecast
forecast(model)
testing
forecast(model,testing)
?forecast
forecast(model,h=length(testing))
length(testing)
testing
testing$X
forecast(model,h=length(testing$X))
result <- forecast(model,h=length(testing$X))
cbind(result, testing)
cbind(result, testing$visitsTumblr)
result
resultcombined <- cbind(result, testing)
pring(resultcombined$visitsTumblr, resultcombined$Lo 95, resultcombined$Hi 95)
print(resultcombined$visitsTumblr, resultcombined$Lo 95, resultcombined$Hi 95)
resultcombined$visitsTumblr, resultcombined$Lo 95, resultcombined$Hi 95
resultcombined$Lo 95
"resultcombined$Lo 95""
"resultcombined$Lo 95""
resultcombined$"Lo 95"
print(resultcombined$visitsTumblr, resultcombined$"Lo 95", resultcombined$"Hi 95")
print(resultcombined$visitsTumblr-resultcombined$"Lo 95")
print(resultcombined$visitsTumblr-resultcombined$"Hi 95")
sum((resultcombined$visitsTumblr-resultcombined$"Hi 95")>0)
sum((resultcombined$visitsTumblr-resultcombined$"Lo 95")<0)
length(resultcombined)
nrows(resultcombined)
nrow(resultcombined)
9/235
1-9/235
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
library(e1071)
?e1071
svm.model <- svm(CompressiveStrength ~ ., data = training)
svm.pred <- predict(svm.model, testing)
svm.pred
confusionMatrix(svm.pred, testing$CompressiveStrength)
rmse <- sqrt(mean((svm.pred-testing$CompressiveStrength)^2))
rmse
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(64233)
model1 <- train(diagnosis~., method="rf", data=training)
model2 <- train(diagnosis~., method="gbm", data=training)
model3 <- train(diagnosis~., method="lda", data=training)
model3 <- train(diagnosis~., method="lda", data=training)
pred1 <- predict(model1, training)
pred2 <- predict(model2, training)
pred3 <- predict(model3, training)
predF <- data.frame(pred1, pred2, pred3, diagnosis=training$diagnosis)
combModFit <- train(diagnosis~.,method="rf",data=predF)
combPred <- predict(combModFit,testing)
combModFit
setwd("~/Data/ebola")
casecounts1 <- read.csv("https://raw.githubusercontent.com/InstituteforDiseaseModeling/EVD/master/sierra_leone_EVD_2014.csv")
library(RCurl)
file1 <- ("https://raw.githubusercontent.com/InstituteforDiseaseModeling/EVD/master/sierra_leone_EVD_2014.csv")
case1 <- csv.read(file1)
library(csv)
file1 <- ("https://raw.githubusercontent.com/InstituteforDiseaseModeling/EVD/master/sierra_leone_EVD_2014.csv")
case1 <- read.csv(file1)
file1 <- getURL("https://raw.githubusercontent.com/InstituteforDiseaseModeling/EVD/master/sierra_leone_EVD_2014.csv")
case1 <- read.csv(file1)
file1 <- getURL("https://raw.githubusercontent.com/InstituteforDiseaseModeling/EVD/master/sierra_leone_EVD_2014.csv")
case1 <- read.csv(text = file1)
case1
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
case1
apply.weekly()
library(xts)
?apply.weekly
str(case1)
?read.csv
shiny::runApp()
file1 <- getURL("https://raw.githubusercontent.com/InstituteforDiseaseModeling/EVD/master/sierra_leone_EVD_2014.csv")
case1 <- read.csv(text = file1, stringsAsFactors = F)
str(case1)
case1$X <- as.Date(case1$X)
?as.Date
case1$X <- as.Date(case1$X, format="%m/%d/%Y")
str(case1)
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
countrylist = vector("a","b","c")
countrylist = vector(["a","b","c"])
countrylist = c("a","b","c")
countrylist[1]
?paste
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
case1
file1
paste("https://raw.githubusercontent.com/InstituteforDiseaseModeling/EVD/master/",countrylist[i], "_EVD_2014.csv",sep="")
i
paste("https://raw.githubusercontent.com/InstituteforDiseaseModeling/EVD/master/",countrylist[strtoi(i)], "_EVD_2014.csv",sep="")
shiny::runApp()
shiny::runApp()
shiny::runApp()
?matplot
shiny::runApp()
shiny::runApp()
melt(casefinal)
library(reshape2)
melt(casefinal)
?melt
colnames(casefinal)
melt(casefinal, id.vars="X")
colnames(melt(casefinal, id.vars="X"))
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
?apply.weekly
apply.weekly(casefinal$X, sum)
shiny::runApp()
shiny::runApp()
casefinal
apply.weekly(casefinal$X, sum)
as.xts(casefinal)
aggregate(.~week(X),data=casefinal,sum)
week(X)
week(casefinal$X)
week(casefinal$X)
aggregate(.~week(X),data=casefinal,sum)
aggregate(week(X)~.,data=casefinal,sum)
?aggregate
aggregate(.,by=week(X),data=casefinal,sum)
aggregate(.,by=week(casefinal$X),data=casefinal,sum)
?ddply
ddply(casefinal, ~week(X), summarise)
ddply(casefinal, ~week(X))
casefinal <- as.table(casefinal)
as.table(casefinal)
summary(casefinal)
str(casefinal)
recast(casefinal, X ~ ., fun.aggregate=sum)
casefinal
recast(casefinal, week(X) ~ ., fun.aggregate=sum)
?recaset
?recast
casefinal$Week <- week(casefinal$X)
casefinal
casefinal$Week <- week(casefinal$X)
casefinal$Month <- week(casefinal$X)
casefinal$Week <- week(casefinal$X)
casefinal$Month <- month(casefinal$X)
head(casefinal)
recast(casefinal, Week ~ ., id.var=X, fun.aggregate=sum)
recast(casefinal, Week ~ ., fun.aggregate=sum)
aggregate(.,by=Week,data=casefinal,sum)
aggregate(.,by=Month,data=casefinal,sum)
aggregate(Week~.,data=casefinal,sum)
aggregate(Month~.,data=casefinal,sum)
aggregate(.~Month,data=casefinal,sum)
?aggregate
casefinal <- data.table(casefinal)
casefinal <- as.data.table(casefinal)
library(data.table)
casefinal <- as.data.table(casefinal)
casefinal[,lapply(list(casefinal[2:ncol(casefinal)]),sum),by = Week]
lapply(list(casefinal[2:ncol(casefinal)]),sum)
list(casefinal[2:ncol(casefinal)])
list(casefinal[2:ncol(casefinal)])
list(casefinal[3:ncol(casefinal)])
casefinal[,lapply(.SD,sum),by = Week]
?lapply
shiny::runApp()
?lapply
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
library(shinyapps)
deployApp()
shiny::runApp()
?cbind
shiny::runApp()
shiny::runApp()
casefinal
case1
merge(casefinal,case1, by=X)
merge(casefinal,case1, by="X")
shiny::runApp()
?sidebarLayout
?mainPanel
?sidebarLayout
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
?plotOutput
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
deployApp()
shiny::runApp()
deployApp()
shiny::runApp()
shiny::runApp()
deployApp()
shiny::runApp()
deployApp()
deployApp()
shiny::runApp('EVD/dashboard')
deployApp()
setwd("~/Data/ebola/EVD/dashboard")
deployApp()
deployApp()
deployApp()
?deployApp
shinyapps::setAccountInfo(
name="institutefordiseasemodeling",
token="AC690423362789A550A2AEDE22AB2C2E",
secret="keoK9pd2vynNIEuzmwFJZeWvFvqLQQqo2RPvXmQk")
deployApp()
